from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import shutil
import tempfile
from pathlib import Path
import os
import sys

# —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å medical_ollama.py –∏–∑ —ç—Ç–æ–π –∂–µ –ø–∞–ø–∫–∏
sys.path.insert(0, str(Path(__file__).parent))
from bot import MedicalAssistant  # –∏–º–ø–æ—Ä—Ç –≤–∞—à–µ–≥–æ –∫–ª–∞—Å—Å–∞

app = FastAPI(title="Medical-Ollama API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

assistant = MedicalAssistant()   # –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ


@app.post("/generate")
async def generate_algorithm(pdf: UploadFile = File(...)):
    if not pdf.filename.lower().endswith(".pdf"):
        raise HTTPException(status_code=400, detail="Only PDF files allowed")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        shutil.copyfileobj(pdf.file, tmp)
        tmp_path = tmp.name

    async def event_stream():
        try:
            sections = assistant.load_guidelines(tmp_path)
            if not sections:
                yield "data: ‚ùå PDF –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤\n\n"
                return
            yield "data: üìñ –ó–∞–≥—Ä—É–∂–µ–Ω—ã —Ä–∞–∑–¥–µ–ª—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É—é –∞–ª–≥–æ—Ä–∏—Ç–º...\n\n"
            # _generate_streaming –ø–∏—à–µ—Ç –≤ —Ñ–∞–π–ª, –Ω–æ –Ω–∞–º –Ω—É–∂–µ–Ω –ø–æ—Ç–æ–∫ –≤ –æ—Ç–≤–µ—Ç.
            # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏–º –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä:
            import io
            buf = io.StringIO()
            # monkey-patch _generate_streaming, —á—Ç–æ–±—ã –ø–∏—Å–∞–ª –≤ buf
            original = assistant._generate_streaming
            def patched(sections, _):
                class FakeFile:
                    def write(self, text):
                        buf.write(text)
                        yield f"data: {text}\n\n"
                    def flush(self): pass
                for token in original(sections, FakeFile()):
                    yield token
            # –ó–∞–ø—É—Å–∫–∞–µ–º
            for token in patched(sections, None):
                yield token
            yield "data: [DONE]\n\n"
        finally:
            os.remove(tmp_path)

    return StreamingResponse(event_stream(), media_type="text/plain")

    def stream_generate(prompt: str) -> Generator[str, None, None]:
        # –ü—Ä–∏–º–µ—Ä: –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º prompt –≤ Ollama –∏ —Å—Ç—Ä–∏–º–∏–º –æ—Ç–≤–µ—Ç
        stream = ollama.chat(
            model="hf.co/unsloth/Mistral-Small-3.2-24B-Instruct-2506-GGUF:Q6_K",
            messages=[{"role": "user", "content": prompt}],
            stream=True,
        )
        for chunk in stream:
            yield chunk["message"]["content"]

    @app.post("/generate-stream")
    async def generate_stream(pdf: UploadFile = File(...)):
        # 1) –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF (–∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã)
        text = (await pdf.read()).decode(errors="ignore")
        prompt = f"–°–æ—Å—Ç–∞–≤—å –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º:\n{text[:4000]}"

        # 2) –≤–µ—Ä–Ω—É—Ç—å SSE-—Å—Ç—Ä–∏–º
        return StreamingResponse(
            stream_generate(prompt),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache", "Connection": "keep-alive"},
        )
